 Standard deviation is a number that represents the "spread" or "dispersion" of a set of data. There are other measures for spread, such as range and variance. Here are some example sets of data, and their standard deviations: The above data sets have the same mean. Deviation means "distance from the mean". "Standard" here means "standardized", meaning the standard deviation and mean are in the same units, unlike variance. For example, if the mean height is 2 meters , the standard deviation might be 0.3 meters , whereas the variance would be 0.09 meters squared . It is convenient to know that at least 75% of the data points always lie within 2 standard deviations of the mean (or around 95% if the distribution is Normal). For example, if the mean is 100, and the standard deviation is 15, then at least 75% of the values are between 70 and 130. If the distribution happens to be Normal, then 95% of the values are between 70 and 130. Generally speaking, IQ test scores are normally distributed and have an average of 100. Someone who is "very bright" is two standard deviations above the mean, meaning an IQ test score of 130. 
